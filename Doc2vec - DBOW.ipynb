{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f0aa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sanke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim import models\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ddcebc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaj ka khel khatam hone k baad england cricket...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purana manjan bech rha hai</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tumhare disappointed se kuch ni hoga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inse bas tiktok banva lo batting ni hoti isse ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bhai cricket par tweets mat kara karo please j...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>gujarati fraud kyu hotey hai? pnbscam</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9161</th>\n",
       "      <td>saala idhar 7 lakh k car loan k liye bank choo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9162</th>\n",
       "      <td>mitron nirav modi ji ka relation india k kaun ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9163</th>\n",
       "      <td>or yahn ek month k education loan ki emi pay n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9164</th>\n",
       "      <td>jis bank me 500 rupye niklwane k liye ghnto kh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9165 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  labels\n",
       "0     aaj ka khel khatam hone k baad england cricket...       0\n",
       "1                            purana manjan bech rha hai       5\n",
       "2                  tumhare disappointed se kuch ni hoga       0\n",
       "3     inse bas tiktok banva lo batting ni hoti isse ...       3\n",
       "4     bhai cricket par tweets mat kara karo please j...       3\n",
       "...                                                 ...     ...\n",
       "9160              gujarati fraud kyu hotey hai? pnbscam       3\n",
       "9161  saala idhar 7 lakh k car loan k liye bank choo...       3\n",
       "9162  mitron nirav modi ji ka relation india k kaun ...       3\n",
       "9163  or yahn ek month k education loan ki emi pay n...       2\n",
       "9164  jis bank me 500 rupye niklwane k liye ghnto kh...       3\n",
       "\n",
       "[9165 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Code Mixed Hindi-English tweets.xlsx')\n",
    "df.drop(['id'],axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ee31f",
   "metadata": {},
   "source": [
    "# Labels are as follows:\n",
    "0 - No emotions,\n",
    "1 - Happy,\n",
    "2 - Sad,\n",
    "3 - Angry,\n",
    "4 - Fear,\n",
    "5 - Disgust,\n",
    "6 - Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7d62f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (9165, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1892\n",
       "3    1763\n",
       "2    1529\n",
       "1    1226\n",
       "5    1147\n",
       "6    1049\n",
       "4     559\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset shape: \", df.shape)\n",
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c51f12",
   "metadata": {},
   "source": [
    "# 1. Models without Removing anything:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a03466",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test &&& Tokenizing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd91f4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['modi', 'ne', 'to', 'ensure', 'kr', 'diya', 'demonetization', 'aur', 'gst', 'unthinkable', 'rates', 'se', 'ki', 'garib', 'marr', 'hi', 'jai', 'ni', 'rha', 'garib', 'aur', 'ni', 'rahegi', 'garibi'], tags=[2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=3)\n",
    "\n",
    "# Creating a function for tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "# Tagging words:\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "\n",
    "train_tagged.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a5677",
   "metadata": {},
   "source": [
    "# Doc2Vec:\n",
    "### Distributed Bag of Words (DBOW)\n",
    "Note: If dm=0, distributed bag of words (PV-DBOW) is used; if dm=1,‘distributed memory’ (PV-DM) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e95d1",
   "metadata": {},
   "source": [
    "### Building DBOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d066bd55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07e3d22ac4049a08653e23cf067b0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279c314755f3475bab20d7bd480905bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedd995afd8b433281f6c27deb033dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42459617e999411586ad53829c084b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c071fc05417a48f68f43daffc256b768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2a854e5d7d4c03adeb5177351409bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b913b7b77314f118f9eaaf94576b4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdaab057c5f44f1a68fc213e6a0ee6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94444ca709345deafa3e960e7c526c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8466192b96834d3c934df7c9b6a25128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ea5d134cb145109c88d00a67389540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0d25b8f9b84baf8092357c7c40b6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b299ed375d4b73b653e7ff2d8bfd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c666ab5ea583448588e5830c6625ddf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b276bb7ee5524b08aef589b45a8c6fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76a02cd2bda4674a49a91089a09434d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3636ef1eb6743c7ba3101f20cd006cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797d062df35e44208ee6e2f5218c266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f508ccc9b4409f8ab4226ba9b6a482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049f0556fa164b36a1f466ba98088cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e302c8c3ca41bfb78439b885901052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d825d35b36f4111bd691d0d6e556333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c2dae13d884d2386861e89db33f008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9845b36109e1448bb587ddfc6a40c92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ce1c89ab014ec7990da2e047186417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9161b0f8294743997a9bee9cdc1f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d0507f6c9e44b59d46dc8a1b6bf251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2179c3d29109442e90268578173e0a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf000c80e69a4954ad1951aea3d0f4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504ea431f92047038b91f21ad9077299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8370bff83334add87401348c97dfe6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dfdf5",
   "metadata": {},
   "source": [
    "### Creating Final feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0870cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Final Feature Vector for the Classifier\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "# Creating X_train, X_test, y_train, y_test\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9fd48",
   "metadata": {},
   "source": [
    "### Base Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd725e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dictionary with four models with some parameters:\n",
    "model_params = {\n",
    "    \n",
    "    'SVC' :{\n",
    "        'model' : SVC(),\n",
    "        'params' : {\n",
    "            'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf','linear','poly','sigmoid']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'logistics_regression' :{\n",
    "        'model' : LogisticRegression(solver = 'lbfgs', multi_class = 'auto'),\n",
    "        'params' : {\n",
    "            'C' : [0.1, 1, 20, 40, 60, 80, 100], 'solver' : ['lbfgs', 'liblinear']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'random_forest' :{\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [80,85,90,95,100], \n",
    "            'max_depth':[20,30,None], 'criterion':['gini','entropy']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33920b",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e658552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[159  20  35  90   8  24  25]\n",
      " [ 79  54  27  37   7   7  31]\n",
      " [ 95  30  55  82   7  14  27]\n",
      " [ 88  31  47 136   8  20  16]\n",
      " [ 30   8  16  11  16   6  17]\n",
      " [ 75  17  17  74   5  35  16]\n",
      " [ 56  23  20  32   7   7  86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.44      0.34       361\n",
      "           1       0.30      0.22      0.25       242\n",
      "           2       0.25      0.18      0.21       310\n",
      "           3       0.29      0.39      0.34       346\n",
      "           4       0.28      0.15      0.20       104\n",
      "           5       0.31      0.15      0.20       239\n",
      "           6       0.39      0.37      0.38       231\n",
      "\n",
      "    accuracy                           0.30      1833\n",
      "   macro avg       0.30      0.27      0.27      1833\n",
      "weighted avg       0.30      0.30      0.28      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[141  36  48  60  10  23  43]\n",
      " [ 70  58  27  32   6   5  44]\n",
      " [ 86  39  61  65   6   8  45]\n",
      " [ 89  36  49 101   9  23  39]\n",
      " [ 28  10  19  11  13   0  23]\n",
      " [ 68  25  22  60   4  33  27]\n",
      " [ 49  25  22  20   3   4 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.39      0.32       361\n",
      "           1       0.25      0.24      0.25       242\n",
      "           2       0.25      0.20      0.22       310\n",
      "           3       0.29      0.29      0.29       346\n",
      "           4       0.25      0.12      0.17       104\n",
      "           5       0.34      0.14      0.20       239\n",
      "           6       0.33      0.47      0.39       231\n",
      "\n",
      "    accuracy                           0.28      1833\n",
      "   macro avg       0.28      0.26      0.26      1833\n",
      "weighted avg       0.28      0.28      0.27      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[146  19  42  82   8  39  25]\n",
      " [ 67  52  38  31   9  15  30]\n",
      " [ 84  26  73  76   6  20  25]\n",
      " [ 88  29  49 113  11  36  20]\n",
      " [ 28   9  19  15  18   3  12]\n",
      " [ 64  15  32  62   6  47  13]\n",
      " [ 49  34  23  34   4   8  79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33       361\n",
      "           1       0.28      0.21      0.24       242\n",
      "           2       0.26      0.24      0.25       310\n",
      "           3       0.27      0.33      0.30       346\n",
      "           4       0.29      0.17      0.22       104\n",
      "           5       0.28      0.20      0.23       239\n",
      "           6       0.39      0.34      0.36       231\n",
      "\n",
      "    accuracy                           0.29      1833\n",
      "   macro avg       0.29      0.27      0.28      1833\n",
      "weighted avg       0.29      0.29      0.28      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 1h 21min 51s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.295145</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.280960</td>\n",
       "      <td>{'C': 20, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.288052</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_esti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0                   SVC    0.295145   \n",
       "1  logistics_regression    0.280960   \n",
       "2         random_forest    0.288052   \n",
       "\n",
       "                                         best_params  \n",
       "0          {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}  \n",
       "1                   {'C': 20, 'solver': 'liblinear'}  \n",
       "2  {'criterion': 'gini', 'max_depth': 20, 'n_esti...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nFitting...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef755593",
   "metadata": {},
   "source": [
    "# 2. Models after removing Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ca219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Code Mixed Hindi-English tweets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577f43c",
   "metadata": {},
   "source": [
    "### Removing Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a20bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Hinglish stopwords which contains 1036 words from both English and Hindi languages\n",
    "# Source: https://github.com/TrigonaMinima/HinglishNLP/blob/master/data/assets/stop_hinglish\n",
    "\n",
    "stopwordlist = ['a', 'aadi', 'aaj', 'aap', 'aapne', 'aata', 'aati', 'aaya', 'aaye', 'ab', 'abbe', 'abbey', 'abe', 'abhi', 'able', 'about', 'above', 'accha', 'according', 'accordingly', 'acha', 'achcha', 'across', 'actually', 'after', 'afterwards', 'again', 'against', 'agar', 'ain', 'aint', \"ain't\", 'aisa', 'aise', 'aisi', 'alag', 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'andar', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'ap', 'apan', 'apart', 'apna', 'apnaa', 'apne', 'apni', 'appear', 'are', 'aren', 'arent', \"aren't\", 'around', 'arre', 'as', 'aside', 'ask', 'asking', 'at', 'aur', 'avum', 'aya', 'aye', 'baad', 'baar', 'bad', 'bahut', 'bana', 'banae', 'banai', 'banao', 'banaya', 'banaye', 'banayi', 'banda', 'bande', 'bandi', 'bane', 'bani', 'bas', 'bata', 'batao', 'bc', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'bhai', 'bheetar', 'bhi', 'bhitar', 'bht', 'bilkul', 'bohot', 'bol', 'bola', 'bole', 'boli', 'bolo', 'bolta', 'bolte', 'bolti', 'both', 'brief', 'bro', 'btw', 'but', 'by', 'came', 'can', 'cannot', 'cant', \"can't\", 'cause', 'causes', 'certain', 'certainly', 'chahiye', 'chaiye', 'chal', 'chalega', 'chhaiye', 'clearly', \"c'mon\", 'com', 'come', 'comes', 'could', 'couldn', 'couldnt', \"couldn't\", 'd', 'de', 'dede', 'dega', 'degi', 'dekh', 'dekha', 'dekhe', 'dekhi', 'dekho', 'denge', 'dhang', 'di', 'did', 'didn', 'didnt', \"didn't\", 'dijiye', 'diya', 'diyaa', 'diye', 'diyo', 'do', 'does', 'doesn', 'doesnt', \"doesn't\", 'doing', 'done', 'dono', 'dont', \"don't\", 'doosra', 'doosre', 'down', 'downwards', 'dude', 'dunga', 'dungi', 'during', 'dusra', 'dusre', 'dusri', 'dvaara', 'dvara', 'dwaara', 'dwara', 'each', 'edu', 'eg', 'eight', 'either', 'ek', 'else', 'elsewhere', 'enough', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'far', 'few', 'fifth', 'fir', 'first', 'five', 'followed', 'following', 'follows', 'for', 'forth', 'four', 'from', 'further', 'furthermore', 'gaya', 'gaye', 'gayi', 'get', 'gets', 'getting', 'ghar', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'good', 'got', 'gotten', 'greetings', 'haan', 'had', 'hadd', 'hadn', 'hadnt', \"hadn't\", 'hai', 'hain', 'hamara', 'hamare', 'hamari', 'hamne', 'han', 'happens', 'har', 'hardly', 'has', 'hasn', 'hasnt', \"hasn't\", 'have', 'haven', 'havent', \"haven't\", 'having', 'he', 'hello', 'help', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', \"here's\", 'hereupon', 'hers', 'herself', \"he's\", 'hi', 'him', 'himself', 'his', 'hither', 'hm', 'hmm', 'ho', 'hoga', 'hoge', 'hogi', 'hona', 'honaa', 'hone', 'honge', 'hongi', 'honi', 'hopefully', 'hota', 'hotaa', 'hote', 'hoti', 'how', 'howbeit', 'however', 'hoyenge', 'hoyengi', 'hu', 'hua', 'hue', 'huh', 'hui', 'hum', 'humein', 'humne', 'hun', 'huye', 'huyi', 'i', \"i'd\", 'idk', 'ie', 'if', \"i'll\", \"i'm\", 'imo', 'in', 'inasmuch', 'inc', 'inhe', 'inhi', 'inho', 'inka', 'inkaa', 'inke', 'inki', 'inn', 'inner', 'inse', 'insofar', 'into', 'inward', 'is', 'ise', 'isi', 'iska', 'iskaa', 'iske', 'iski', 'isme', 'isn', 'isne', 'isnt', \"isn't\", 'iss', 'isse', 'issi', 'isski', 'it', \"it'd\", \"it'll\", 'itna', 'itne', 'itni', 'itno', 'its', \"it's\", 'itself', 'ityaadi', 'ityadi', \"i've\", 'ja', 'jaa', 'jab', 'jabh', 'jaha', 'jahaan', 'jahan', 'jaisa', 'jaise', 'jaisi', 'jata', 'jayega', 'jidhar', 'jin', 'jinhe', 'jinhi', 'jinho', 'jinhone', 'jinka', 'jinke', 'jinki', 'jinn', 'jis', 'jise', 'jiska', 'jiske', 'jiski', 'jisme', 'jiss', 'jisse', 'jitna', 'jitne', 'jitni', 'jo', 'just', 'jyaada', 'jyada', 'k', 'ka', 'kaafi', 'kab', 'kabhi', 'kafi', 'kaha', 'kahaa', 'kahaan', 'kahan', 'kahi', 'kahin', 'kahte', 'kaisa', 'kaise', 'kaisi', 'kal', 'kam', 'kar', 'kara', 'kare', 'karega', 'karegi', 'karen', 'karenge', 'kari', 'karke', 'karna', 'karne', 'karni', 'karo', 'karta', 'karte', 'karti', 'karu', 'karun', 'karunga', 'karungi', 'kaun', 'kaunsa', 'kayi', 'kch', 'ke', 'keep', 'keeps', 'keh', 'kehte', 'kept', 'khud', 'ki', 'kin', 'kine', 'kinhe', 'kinho', 'kinka', 'kinke', 'kinki', 'kinko', 'kinn', 'kino', 'kis', 'kise', 'kisi', 'kiska', 'kiske', 'kiski', 'kisko', 'kisliye', 'kisne', 'kitna', 'kitne', 'kitni', 'kitno', 'kiya', 'kiye', 'know', 'known', 'knows', 'ko', 'koi', 'kon', 'konsa', 'koyi', 'krna', 'krne', 'kuch', 'kuchch', 'kuchh', 'kul', 'kull', 'kya', 'kyaa', 'kyu', 'kyuki', 'kyun', 'kyunki', 'lagta', 'lagte', 'lagti', 'last', 'lately', 'later', 'le', 'least', 'lekar', 'lekin', 'less', 'lest', 'let', \"let's\", 'li', 'like', 'liked', 'likely', 'little', 'liya', 'liye', 'll', 'lo', 'log', 'logon', 'lol', 'look', 'looking', 'looks', 'ltd', 'lunga', 'm', 'maan', 'maana', 'maane', 'maani', 'maano', 'magar', 'mai', 'main', 'maine', 'mainly', 'mana', 'mane', 'mani', 'mano', 'many', 'mat', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'mein', 'mera', 'mere', 'merely', 'meri', 'might', 'mightn', 'mightnt', \"mightn't\", 'mil', 'mjhe', 'more', 'moreover', 'most', 'mostly', 'much', 'mujhe', 'must', 'mustn', 'mustnt', \"mustn't\", 'my', 'myself', 'na', 'naa', 'naah', 'nahi', 'nahin', 'nai', 'name', 'namely', 'nd', 'ne', 'near', 'nearly', 'necessary', 'neeche', 'need', 'needn', 'neednt', \"needn't\", 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nhi', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nope', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'par', 'pata', 'pe', 'pehla', 'pehle', 'pehli', 'people', 'per', 'perhaps', 'phla', 'phle', 'phli', 'placed', 'please', 'plus', 'poora', 'poori', 'provides', 'pura', 'puri', 'q', 'que', 'quite', 'raha', 'rahaa', 'rahe', 'rahi', 'rakh', 'rakha', 'rakhe', 'rakhen', 'rakhi', 'rakho', 'rather', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'rehte', 'rha', 'rhaa', 'rhe', 'rhi', 'ri', 'right', 's', 'sa', 'saara', 'saare', 'saath', 'sab', 'sabhi', 'sabse', 'sahi', 'said', 'sakta', 'saktaa', 'sakte', 'sakti', 'same', 'sang', 'sara', 'sath', 'saw', 'say', 'saying', 'says', 'se', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'shan', 'shant', \"shan't\", 'she', \"she's\", 'should', 'shouldn', 'shouldnt', \"shouldn't\", \"should've\", 'si', 'since', 'six', 'so', 'soch', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'still', 'sub', 'such', 'sup', 'sure', 't', 'tab', 'tabh', 'tak', 'take', 'taken', 'tarah', 'teen', 'teeno', 'teesra', 'teesre', 'teesri', 'tell', 'tends', 'tera', 'tere', 'teri', 'th', 'tha', 'than', 'thank', 'thanks', 'thanx', 'that', \"that'll\", 'thats', \"that's\", 'the', 'theek', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'theres', \"there's\", 'thereupon', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'thi', 'thik', 'thing', 'think', 'thinking', 'third', 'this', 'tho', 'thoda', 'thodi', 'thorough', 'thoroughly', 'those', 'though', 'thought', 'three', 'through', 'throughout', 'thru', 'thus', 'tjhe', 'to', 'together', 'toh', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'true', 'truly', 'try', 'trying', 'tu', 'tujhe', 'tum', 'tumhara', 'tumhare', 'tumhari', 'tune', 'twice', 'two', 'um', 'umm', 'un', 'under', 'unhe', 'unhi', 'unho', 'unhone', 'unka', 'unkaa', 'unke', 'unki', 'unko', 'unless', 'unlikely', 'unn', 'unse', 'until', 'unto', 'up', 'upar', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'usi', 'using', 'uska', 'uske', 'usne', 'uss', 'usse', 'ussi', 'usually', 'vaala', 'vaale', 'vaali', 'vahaan', 'vahan', 'vahi', 'vahin', 'vaisa', 'vaise', 'vaisi', 'vala', 'vale', 'vali', 'various', 've', 'very', 'via', 'viz', 'vo', 'waala', 'waale', 'waali', 'wagaira', 'wagairah', 'wagerah', 'waha', 'wahaan', 'wahan', 'wahi', 'wahin', 'waisa', 'waise', 'waisi', 'wala', 'wale', 'wali', 'want', 'wants', 'was', 'wasn', 'wasnt', \"wasn't\", 'way', 'we', \"we'd\", 'well', \"we'll\", 'went', 'were', \"we're\", 'weren', 'werent', \"weren't\", \"we've\", 'what', 'whatever', \"what's\", 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', \"where's\", 'whereupon', 'wherever', 'whether', 'which', 'while', 'who', 'whoever', 'whole', 'whom', \"who's\", 'whose', 'why', 'will', 'willing', 'with', 'within', 'without', 'wo', 'woh', 'wohi', 'won', 'wont', \"won't\", 'would', 'wouldn', 'wouldnt', \"wouldn't\", 'y', 'ya', 'yadi', 'yah', 'yaha', 'yahaan', 'yahan', 'yahi', 'yahin', 'ye', 'yeah', 'yeh', 'yehi', 'yes', 'yet', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\", 'yup']\n",
    "\n",
    "STOPWORDS = set(stopwordlist)\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda text: cleaning_stopwords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1e8b5",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test &&& Tokenizing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "135453c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['modi', 'ensure', 'kr', 'demonetization', 'gst', 'unthinkable', 'rates', 'garib', 'marr', 'jai', 'ni', 'garib', 'ni', 'rahegi', 'garibi'], tags=[2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=3)\n",
    "\n",
    "# Creating a function for tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "# Tagging words:\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "\n",
    "train_tagged.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac274a",
   "metadata": {},
   "source": [
    "# Doc2Vec:\n",
    "### Distributed Bag of Words (DBOW)\n",
    "Note: If dm=0, distributed bag of words (PV-DBOW) is used; if dm=1,‘distributed memory’ (PV-DM) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443bbbcd",
   "metadata": {},
   "source": [
    "### Building DBOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee1a2c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87fbd81a7be4df1a60be28951cee64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b018c5384bf642d5b26ecb3fdc0058ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b30642921bc44a6a98dd0bfc0673c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d41bdcfbac94a5ea0d23f551ce0ca12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bc51ce88394a13893dbd9c2b9a997c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287ab31a991b409b9e33787790b45aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcee965133842a1a26e464a69545b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a13634d67fe4e8a979545e7dd1af1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8295bab8ae144435aaf0f5c134e2cd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d96f40c5574227a0af2cf03f9dea55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599b7aab20ec4fec8aa6427f330455ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e0e54503884d2f87dc2ddc65882202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04658d3bcf65448780973c3527441fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70e632579d14a308982ec63074b43e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13763681c7b24198b08913e30566cddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4a24e6821448fc9379f59ec9ccd6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e9579b89b5489f8bbdfa33060f5855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c492f609bc741c8b743435ea2a62748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afddd41de7a0401ba2e2339a9957aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d8c71be6a8478faaa9df77b84d60cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35503c4d098440d4b159dd339288510a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d706d40534224b4a89793b0e4c786a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753a8060614c43a188205625e5841c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23298b9df2c4ab88bfc69db689d3b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eac63656314b67a5c01dc89aac9086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1cbe65f53645f28b8b78c5282fbaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee497e24fce4ddaa6c55c540002ef35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1de2e82c3dc43e1a0e7e9aa9500c591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826b74b713404325b6f763c3c41449c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50c3709bc88485a8df89ac835a7e994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5eb630d6d0465294364217086a0a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d30df",
   "metadata": {},
   "source": [
    "### Creating Final feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7250a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Final Feature Vector for the Classifier\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "# Creating X_train, X_test, y_train, y_test\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff085aa",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9cc8ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[136  23  56  77   6  30  33]\n",
      " [ 52 101  24  32   3   9  21]\n",
      " [ 92  23 103  41  10  26  15]\n",
      " [ 71  24  56 135  11  36  13]\n",
      " [ 32   9  14   9  17  12  11]\n",
      " [ 54   7  37  47   5  77  12]\n",
      " [ 57  19  17  24   4  13  97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.38      0.32       361\n",
      "           1       0.49      0.42      0.45       242\n",
      "           2       0.34      0.33      0.33       310\n",
      "           3       0.37      0.39      0.38       346\n",
      "           4       0.30      0.16      0.21       104\n",
      "           5       0.38      0.32      0.35       239\n",
      "           6       0.48      0.42      0.45       231\n",
      "\n",
      "    accuracy                           0.36      1833\n",
      "   macro avg       0.38      0.35      0.36      1833\n",
      "weighted avg       0.37      0.36      0.36      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[130  31  55  71   3  27  44]\n",
      " [ 32 113  27  32   3   7  28]\n",
      " [ 88  34  98  37   8  24  21]\n",
      " [ 68  32  57 122  12  34  21]\n",
      " [ 31  14  12   9  14   6  18]\n",
      " [ 51  13  33  52   4  71  15]\n",
      " [ 46  26  19  24   4  12 100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.36      0.32       361\n",
      "           1       0.43      0.47      0.45       242\n",
      "           2       0.33      0.32      0.32       310\n",
      "           3       0.35      0.35      0.35       346\n",
      "           4       0.29      0.13      0.18       104\n",
      "           5       0.39      0.30      0.34       239\n",
      "           6       0.40      0.43      0.42       231\n",
      "\n",
      "    accuracy                           0.35      1833\n",
      "   macro avg       0.36      0.34      0.34      1833\n",
      "weighted avg       0.35      0.35      0.35      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[144  22  56  72   4  27  36]\n",
      " [ 45 102  23  35   3   9  25]\n",
      " [ 93  26  95  48   7  23  18]\n",
      " [ 79  22  59 138   4  32  12]\n",
      " [ 32   8  15  10  12  14  13]\n",
      " [ 48   9  36  56   5  69  16]\n",
      " [ 55  23  15  27   3  17  91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.34       361\n",
      "           1       0.48      0.42      0.45       242\n",
      "           2       0.32      0.31      0.31       310\n",
      "           3       0.36      0.40      0.38       346\n",
      "           4       0.32      0.12      0.17       104\n",
      "           5       0.36      0.29      0.32       239\n",
      "           6       0.43      0.39      0.41       231\n",
      "\n",
      "    accuracy                           0.36      1833\n",
      "   macro avg       0.37      0.33      0.34      1833\n",
      "weighted avg       0.36      0.36      0.35      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 26min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.363339</td>\n",
       "      <td>{'C': 100, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.353519</td>\n",
       "      <td>{'C': 80, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.355155</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 30, 'n_e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0                   SVC    0.363339   \n",
       "1  logistics_regression    0.353519   \n",
       "2         random_forest    0.355155   \n",
       "\n",
       "                                         best_params  \n",
       "0            {'C': 100, 'gamma': 1, 'kernel': 'rbf'}  \n",
       "1                   {'C': 80, 'solver': 'liblinear'}  \n",
       "2  {'criterion': 'entropy', 'max_depth': 30, 'n_e...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nFitting...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe63e9a",
   "metadata": {},
   "source": [
    "# 3. Model after removing repeating characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36d9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Code Mixed Hindi-English tweets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60097431",
   "metadata": {},
   "source": [
    "### Removing repeating characteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a54781ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = (word_tokenize(i) for i in df.tweets)\n",
    "df['tweets'] = df['tweets'].apply(nltk.word_tokenize)\n",
    "\n",
    "pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "def reduce_sequence_word(word):\n",
    "    return ''.join([match.group()[:2] if len(match.group()) > 2 else match.group() for match in pattern.finditer(word)])\n",
    "\n",
    "def reduce_sequence_tweet(tweet):\n",
    "    return [reduce_sequence_word(word) for word in tweet]\n",
    "\n",
    "df.tweets = df.tweets.apply(lambda tweet: reduce_sequence_tweet(tweet))\n",
    "df['tweets'] = df['tweets'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a9230",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test &&& Tokenizing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c727bc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=[\"'modi\", \"'ne\", \"'to\", \"'ensure\", \"'kr\", \"'diya\", \"'demonetization\", \"'aur\", \"'gst\", \"'unthinkable\", \"'rates\", \"'se\", \"'ki\", \"'garib\", \"'marr\", \"'hi\", \"'jai\", \"'ni\", \"'rha\", \"'garib\", \"'aur\", \"'ni\", \"'rahegi\", \"'garibi\"], tags=[2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=3)\n",
    "\n",
    "# Creating a function for tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "# Tagging words:\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "\n",
    "train_tagged.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ed241",
   "metadata": {},
   "source": [
    "# Doc2Vec:\n",
    "### Distributed Bag of Words (DBOW)\n",
    "Note: If dm=0, distributed bag of words (PV-DBOW) is used; if dm=1,‘distributed memory’ (PV-DM) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0d940",
   "metadata": {},
   "source": [
    "### Building DBOW model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1c8d62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc7ba0969254969bd84fa2fa4a60894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55629bf675c04f519e8fc69db5a8b545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b06870ebf24c7da9ad05dba9407a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd20923972454d1ab746e7d3bdff5da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8b962355d14a35b7711356d15b853b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82daf9b0237342a5bb97913cb699392a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8675c986b3244b1a0c1eb4307f1ca61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d782e7a65bd04dbabf5c4db7213394bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee31ef1cff3f4fa8b0b96346485c9c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fda0a8150aa40d5ade1deaaa4d11c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac5e0c3c741483f8ecfbb23c15b417d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe92f73ef7949d4883e6e92d238ee00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92cdfbfd7ea44f1b416abd8b7cf3fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c97ae233af41a7b62d97381638c7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72011fb741d443eea9400885ec9509dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622175af27e043a2a4ad28156d907afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338aa58a0dec4390b03fbac01d34cb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c3f01194c14889ac57274da4ca8b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040d60ffceea4ab8927d866217f5f76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a1cb3561d344fc8d05eabebcec7dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bccbf3e22714bcf8257942cd1485756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a9bb74e74a40be8e8655705882df49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a7c25fae36449ab29143191d9ad2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a70c9880e3a49fda1e132667fd73491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4099e69fe74341b7b99582e9ddedfceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78beed34c26b4c51872796d9fbdda92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bdc94686b941da9a9ff0a80456cc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66fa5a66a5b4575a0f984e3d1a501bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a20e8b27cf463295338588f2b715a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9751c5fa13b144d68c1adf44c4661038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26e0ce369ca40a482951b0d64bebe8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc9de5",
   "metadata": {},
   "source": [
    "### Creating Final feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "169abf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Final Feature Vector for the Classifier\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "# Creating X_train, X_test, y_train, y_test\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddabc4a2",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a74723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[148  29  41  97   2  21  23]\n",
      " [ 67  60  29  38   2  18  28]\n",
      " [ 86  32  69  81   2  20  20]\n",
      " [ 79  25  51 153   5  25   8]\n",
      " [ 25  10  24  15  12   4  14]\n",
      " [ 66  17  39  76   7  28   6]\n",
      " [ 57  30  22  31   4   9  78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.41      0.33       361\n",
      "           1       0.30      0.25      0.27       242\n",
      "           2       0.25      0.22      0.24       310\n",
      "           3       0.31      0.44      0.37       346\n",
      "           4       0.35      0.12      0.17       104\n",
      "           5       0.22      0.12      0.15       239\n",
      "           6       0.44      0.34      0.38       231\n",
      "\n",
      "    accuracy                           0.30      1833\n",
      "   macro avg       0.31      0.27      0.27      1833\n",
      "weighted avg       0.30      0.30      0.29      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[141  42  37  77   7  17  40]\n",
      " [ 69  67  23  29   4  13  37]\n",
      " [ 85  43  69  60   8  17  28]\n",
      " [ 89  33  57 121   2  17  27]\n",
      " [ 27  13  20   6  11   5  22]\n",
      " [ 66  22  42  64   9  16  20]\n",
      " [ 55  27  21  27   1   2  98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.39      0.32       361\n",
      "           1       0.27      0.28      0.27       242\n",
      "           2       0.26      0.22      0.24       310\n",
      "           3       0.32      0.35      0.33       346\n",
      "           4       0.26      0.11      0.15       104\n",
      "           5       0.18      0.07      0.10       239\n",
      "           6       0.36      0.42      0.39       231\n",
      "\n",
      "    accuracy                           0.29      1833\n",
      "   macro avg       0.27      0.26      0.26      1833\n",
      "weighted avg       0.28      0.29      0.27      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[149  28  44  85   9  30  16]\n",
      " [ 63  53  35  42   8  20  21]\n",
      " [100  36  67  66   3  24  14]\n",
      " [ 73  22  66 137   8  29  11]\n",
      " [ 23   7  25  13  17   7  12]\n",
      " [ 69  15  42  62  12  29  10]\n",
      " [ 41  32  35  26  10   8  79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.41      0.34       361\n",
      "           1       0.27      0.22      0.24       242\n",
      "           2       0.21      0.22      0.21       310\n",
      "           3       0.32      0.40      0.35       346\n",
      "           4       0.25      0.16      0.20       104\n",
      "           5       0.20      0.12      0.15       239\n",
      "           6       0.48      0.34      0.40       231\n",
      "\n",
      "    accuracy                           0.29      1833\n",
      "   macro avg       0.29      0.27      0.27      1833\n",
      "weighted avg       0.29      0.29      0.28      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 1h 20min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.298963</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.285325</td>\n",
       "      <td>{'C': 60, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.289689</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0                   SVC    0.298963   \n",
       "1  logistics_regression    0.285325   \n",
       "2         random_forest    0.289689   \n",
       "\n",
       "                                         best_params  \n",
       "0          {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}  \n",
       "1                   {'C': 60, 'solver': 'liblinear'}  \n",
       "2  {'criterion': 'gini', 'max_depth': None, 'n_es...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nFitting...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd80255d",
   "metadata": {},
   "source": [
    "# 4. Models after removing Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88aaf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Code Mixed Hindi-English tweets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c1a50",
   "metadata": {},
   "source": [
    "### Removing Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6674643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "178faf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b7f2b",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test &&& Tokenizing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49563077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['modi', 'ne', 'to', 'ensure', 'kr', 'diya', 'demonetization', 'aur', 'gst', 'unthinkable', 'rates', 'se', 'ki', 'garib', 'marr', 'hi', 'jai', 'ni', 'rha', 'garib', 'aur', 'ni', 'rahegi', 'garibi'], tags=[2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=3)\n",
    "\n",
    "# Creating a function for tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "# Tagging words:\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "\n",
    "train_tagged.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b9ba5",
   "metadata": {},
   "source": [
    "# Doc2Vec:\n",
    "### Distributed Bag of Words (DBOW)\n",
    "Note: If dm=0, distributed bag of words (PV-DBOW) is used; if dm=1,‘distributed memory’ (PV-DM) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ca393",
   "metadata": {},
   "source": [
    "### Building DBOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49253dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a44ded2c9a248c4a0ba437db0c0acab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8ed533ff224f299fe16ade12396bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3504cb77f07845bc86b437a789ecc068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfd0ce4cf914d0b888ea9e4c721cbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60664907ec1e4e1ba35039b75cd807db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce130c35a2340369d1e718b8a4cd52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6cec61be23421894e74f0db4ff670c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53aa3e26daaa484f9a5295903813bdcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542b7606030048e2aca9aa664dd3ff0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac84cdf794744e2dad0f58c559339cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066eed41f7d54881ac6508587f081272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bbdf8a0f8c4b5aaddcfc10fa590fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920b3ab6154c4abc896cddc8abf5546a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713deae465104cd2ae0abe1bf8882255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98877b5afb2d475fa365f1f1397b338f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5f74aff12144969f669f69aa06b50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd754fa355543a4b8446b7d0cb74040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3c7f414c1d497e925909828c9b289f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c10ddee225c4c1d985301108cdf5e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7789c409d0ba4dab8bcab4f1538a7a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4a48db19cb4a30a5ba611eff96cc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf23138a496c4c46992f96c3198c5379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02414a7b614148378be30d2a2cf51f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72946cbea5d348e3810268016a50ea9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12407408572c4b97a7cded48547a220f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fe5e63a50c44bc8e452b50e47904e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a23ddda7aac435783f47abf4aa72050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04809980c0b74b53b1ff5570f839fb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee40a5352e7243b6a6afa0490acb6cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b0a2295a954e318686a672dc8f5998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89fe586a97944d1bce622c15bd3002a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0c92d",
   "metadata": {},
   "source": [
    "### Creating Final feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc84096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Final Feature Vector for the Classifier\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "# Creating X_train, X_test, y_train, y_test\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d741b31",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc0ab1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[163  31  43  84   4  19  17]\n",
      " [ 65  62  31  35   9  17  23]\n",
      " [ 93  38  61  76   7  16  19]\n",
      " [ 98  26  42 138   5  27  10]\n",
      " [ 32   4  19  23  10   7   9]\n",
      " [ 65  21  29  74   6  38   6]\n",
      " [ 55  25  30  23   9  14  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.45      0.35       361\n",
      "           1       0.30      0.26      0.28       242\n",
      "           2       0.24      0.20      0.22       310\n",
      "           3       0.30      0.40      0.35       346\n",
      "           4       0.20      0.10      0.13       104\n",
      "           5       0.28      0.16      0.20       239\n",
      "           6       0.47      0.32      0.38       231\n",
      "\n",
      "    accuracy                           0.30      1833\n",
      "   macro avg       0.30      0.27      0.27      1833\n",
      "weighted avg       0.30      0.30      0.29      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[146  45  41  73   6  17  33]\n",
      " [ 69  75  25  25   7  10  31]\n",
      " [ 97  42  60  62  10  13  26]\n",
      " [108  39  34 112   5  23  25]\n",
      " [ 30   5  15  17  10   6  21]\n",
      " [ 63  33  32  59   9  26  17]\n",
      " [ 48  29  23  17   5  12  97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.40      0.32       361\n",
      "           1       0.28      0.31      0.29       242\n",
      "           2       0.26      0.19      0.22       310\n",
      "           3       0.31      0.32      0.32       346\n",
      "           4       0.19      0.10      0.13       104\n",
      "           5       0.24      0.11      0.15       239\n",
      "           6       0.39      0.42      0.40       231\n",
      "\n",
      "    accuracy                           0.29      1833\n",
      "   macro avg       0.28      0.27      0.26      1833\n",
      "weighted avg       0.28      0.29      0.28      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[141  29  44  90   8  28  21]\n",
      " [ 63  56  40  37   8  18  20]\n",
      " [ 81  40  62  71  10  25  21]\n",
      " [ 94  29  52 119   5  36  11]\n",
      " [ 29   8  19  17  11   7  13]\n",
      " [ 56  21  34  70   4  46   8]\n",
      " [ 52  22  36  29   5  12  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.39      0.32       361\n",
      "           1       0.27      0.23      0.25       242\n",
      "           2       0.22      0.20      0.21       310\n",
      "           3       0.27      0.34      0.31       346\n",
      "           4       0.22      0.11      0.14       104\n",
      "           5       0.27      0.19      0.22       239\n",
      "           6       0.44      0.32      0.38       231\n",
      "\n",
      "    accuracy                           0.28      1833\n",
      "   macro avg       0.28      0.26      0.26      1833\n",
      "weighted avg       0.28      0.28      0.27      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 1h 2min 57s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.298418</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.286961</td>\n",
       "      <td>{'C': 80, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.278232</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_esti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0                   SVC    0.298418   \n",
       "1  logistics_regression    0.286961   \n",
       "2         random_forest    0.278232   \n",
       "\n",
       "                                         best_params  \n",
       "0          {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}  \n",
       "1                   {'C': 80, 'solver': 'liblinear'}  \n",
       "2  {'criterion': 'gini', 'max_depth': 20, 'n_esti...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nFitting...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733ac81",
   "metadata": {},
   "source": [
    "# 5. Models after removing numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e61947f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Code Mixed Hindi-English tweets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d33628",
   "metadata": {},
   "source": [
    "### Removing numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a5996f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda text: cleaning_numbers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d0868",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test &&& Tokenizing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ec4e770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['modi', 'ne', 'to', 'ensure', 'kr', 'diya', 'demonetization', 'aur', 'gst', 'unthinkable', 'rates', 'se', 'ki', 'garib', 'marr', 'hi', 'jai', 'ni', 'rha', 'garib', 'aur', 'ni', 'rahegi', 'garibi'], tags=[2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=3)\n",
    "\n",
    "# Creating a function for tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "# Tagging words:\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "\n",
    "train_tagged.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a57b3e",
   "metadata": {},
   "source": [
    "# Doc2Vec:\n",
    "### Distributed Bag of Words (DBOW)\n",
    "Note: If dm=0, distributed bag of words (PV-DBOW) is used; if dm=1,‘distributed memory’ (PV-DM) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b745fc",
   "metadata": {},
   "source": [
    "### Building DBOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5579c134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d896a41b804296a0cd79c3510f6635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57834d2b2114e6eba6eaa119e566693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57868f79e3fa4df1a9c796cde57007fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df444a2441d145fda2f76558a6ced241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6eeaf7ef274daf980ce5dac20bce24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6496171c91c412daeae9202556800fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee9527ea4214b239e4feafa3aaf39b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc615c4ba104ebba33e4af5cb66511d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115c2be332fd430195aaa488b3f7d4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfd77d61c73444ca715f8fef1238202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8a9827c83642b8adb4f5da8aeedc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daec7f95129a447a8a0a2198accb0f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7700d27de713476da73e0063aee042b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf345a349f948d9ba8b5ed1d969ead0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64beebbbe19741058c48b720f1f14b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fe149c381842daaa346bc7e5b4617c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e57ff0b300434db3e552317bc93b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a9c362d9bf4621a1cfa352a51f6e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2f19be602b42b186bd7ca833ca7d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a1a7df211a4ae587c1a76f72d68371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5938dd2c174c7a9a5b701a3160db9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e86a3a0dfd45ea8fe7b3e930c513c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a1cd607e82403f9f885023ab2708c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3082343403604aca9f8eade1fb1adeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96dd21b9d924bcb843b99cf4b0151fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e855894365b94b80aedb97ba5a02d508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b37ef0c29394a2c955691262712ee66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24401f1bf3749bdbbd6348a89ca8088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859d8d64e35846799cda1dbc9b04a88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6643d6ae95640c59fdbd851ce521a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77cd17cb9104269be8ffa8bcf6e30aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb6a23",
   "metadata": {},
   "source": [
    "### Creating Final feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1795fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Final Feature Vector for the Classifier\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "# Creating X_train, X_test, y_train, y_test\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086bfaa5",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cb56860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[147  35  51  87   5  17  19]\n",
      " [ 71  59  31  41   6   8  26]\n",
      " [ 98  34  64  77   8  17  12]\n",
      " [ 77  27  71 141   4  16  10]\n",
      " [ 36   8  12  23  14   5   6]\n",
      " [ 73  16  35  67   5  30  13]\n",
      " [ 58  27  23  27   7   9  80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.41      0.32       361\n",
      "           1       0.29      0.24      0.26       242\n",
      "           2       0.22      0.21      0.21       310\n",
      "           3       0.30      0.41      0.35       346\n",
      "           4       0.29      0.13      0.18       104\n",
      "           5       0.29      0.13      0.18       239\n",
      "           6       0.48      0.35      0.40       231\n",
      "\n",
      "    accuracy                           0.29      1833\n",
      "   macro avg       0.31      0.27      0.27      1833\n",
      "weighted avg       0.30      0.29      0.28      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[151  38  50  61   4  19  38]\n",
      " [ 54  73  30  31   4   7  43]\n",
      " [101  42  54  55   7  19  32]\n",
      " [110  32  42 110   7  19  26]\n",
      " [ 38  14   8  17  10   1  16]\n",
      " [ 70  26  33  51   7  25  27]\n",
      " [ 48  30  19  19   5   6 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.42      0.32       361\n",
      "           1       0.29      0.30      0.29       242\n",
      "           2       0.23      0.17      0.20       310\n",
      "           3       0.32      0.32      0.32       346\n",
      "           4       0.23      0.10      0.14       104\n",
      "           5       0.26      0.10      0.15       239\n",
      "           6       0.36      0.45      0.40       231\n",
      "\n",
      "    accuracy                           0.29      1833\n",
      "   macro avg       0.28      0.27      0.26      1833\n",
      "weighted avg       0.28      0.29      0.27      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[140  33  64  79   1  29  15]\n",
      " [ 63  54  35  46   3  19  22]\n",
      " [ 83  36  70  73   7  22  19]\n",
      " [ 82  28  60 128   3  31  14]\n",
      " [ 35   6  10  23  16   5   9]\n",
      " [ 58  21  38  64   7  38  13]\n",
      " [ 54  23  31  27   3   9  84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.39      0.32       361\n",
      "           1       0.27      0.22      0.24       242\n",
      "           2       0.23      0.23      0.23       310\n",
      "           3       0.29      0.37      0.33       346\n",
      "           4       0.40      0.15      0.22       104\n",
      "           5       0.25      0.16      0.19       239\n",
      "           6       0.48      0.36      0.41       231\n",
      "\n",
      "    accuracy                           0.29      1833\n",
      "   macro avg       0.31      0.27      0.28      1833\n",
      "weighted avg       0.30      0.29      0.28      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 1h 43min 42s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.291871</td>\n",
       "      <td>{'C': 100, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.287507</td>\n",
       "      <td>{'C': 60, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.289143</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'n_esti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0                   SVC    0.291871   \n",
       "1  logistics_regression    0.287507   \n",
       "2         random_forest    0.289143   \n",
       "\n",
       "                                         best_params  \n",
       "0            {'C': 100, 'gamma': 1, 'kernel': 'rbf'}  \n",
       "1                   {'C': 60, 'solver': 'liblinear'}  \n",
       "2  {'criterion': 'gini', 'max_depth': 20, 'n_esti...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nFitting...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a22af6",
   "metadata": {},
   "source": [
    "# 6. Models after removing all the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "308eb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Code Mixed Hindi-English tweets.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f1a20",
   "metadata": {},
   "source": [
    "### Removing Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f773113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d704c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bd63d",
   "metadata": {},
   "source": [
    "### Removing Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ee9405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Hinglish stopwords which contains 1036 words from both English and Hindi languages\n",
    "# Source: https://github.com/TrigonaMinima/HinglishNLP/blob/master/data/assets/stop_hinglish\n",
    "\n",
    "stopwordlist = ['a', 'aadi', 'aaj', 'aap', 'aapne', 'aata', 'aati', 'aaya', 'aaye', 'ab', 'abbe', 'abbey', 'abe', 'abhi', 'able', 'about', 'above', 'accha', 'according', 'accordingly', 'acha', 'achcha', 'across', 'actually', 'after', 'afterwards', 'again', 'against', 'agar', 'ain', 'aint', \"ain't\", 'aisa', 'aise', 'aisi', 'alag', 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'andar', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'ap', 'apan', 'apart', 'apna', 'apnaa', 'apne', 'apni', 'appear', 'are', 'aren', 'arent', \"aren't\", 'around', 'arre', 'as', 'aside', 'ask', 'asking', 'at', 'aur', 'avum', 'aya', 'aye', 'baad', 'baar', 'bad', 'bahut', 'bana', 'banae', 'banai', 'banao', 'banaya', 'banaye', 'banayi', 'banda', 'bande', 'bandi', 'bane', 'bani', 'bas', 'bata', 'batao', 'bc', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'bhai', 'bheetar', 'bhi', 'bhitar', 'bht', 'bilkul', 'bohot', 'bol', 'bola', 'bole', 'boli', 'bolo', 'bolta', 'bolte', 'bolti', 'both', 'brief', 'bro', 'btw', 'but', 'by', 'came', 'can', 'cannot', 'cant', \"can't\", 'cause', 'causes', 'certain', 'certainly', 'chahiye', 'chaiye', 'chal', 'chalega', 'chhaiye', 'clearly', \"c'mon\", 'com', 'come', 'comes', 'could', 'couldn', 'couldnt', \"couldn't\", 'd', 'de', 'dede', 'dega', 'degi', 'dekh', 'dekha', 'dekhe', 'dekhi', 'dekho', 'denge', 'dhang', 'di', 'did', 'didn', 'didnt', \"didn't\", 'dijiye', 'diya', 'diyaa', 'diye', 'diyo', 'do', 'does', 'doesn', 'doesnt', \"doesn't\", 'doing', 'done', 'dono', 'dont', \"don't\", 'doosra', 'doosre', 'down', 'downwards', 'dude', 'dunga', 'dungi', 'during', 'dusra', 'dusre', 'dusri', 'dvaara', 'dvara', 'dwaara', 'dwara', 'each', 'edu', 'eg', 'eight', 'either', 'ek', 'else', 'elsewhere', 'enough', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'far', 'few', 'fifth', 'fir', 'first', 'five', 'followed', 'following', 'follows', 'for', 'forth', 'four', 'from', 'further', 'furthermore', 'gaya', 'gaye', 'gayi', 'get', 'gets', 'getting', 'ghar', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'good', 'got', 'gotten', 'greetings', 'haan', 'had', 'hadd', 'hadn', 'hadnt', \"hadn't\", 'hai', 'hain', 'hamara', 'hamare', 'hamari', 'hamne', 'han', 'happens', 'har', 'hardly', 'has', 'hasn', 'hasnt', \"hasn't\", 'have', 'haven', 'havent', \"haven't\", 'having', 'he', 'hello', 'help', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', \"here's\", 'hereupon', 'hers', 'herself', \"he's\", 'hi', 'him', 'himself', 'his', 'hither', 'hm', 'hmm', 'ho', 'hoga', 'hoge', 'hogi', 'hona', 'honaa', 'hone', 'honge', 'hongi', 'honi', 'hopefully', 'hota', 'hotaa', 'hote', 'hoti', 'how', 'howbeit', 'however', 'hoyenge', 'hoyengi', 'hu', 'hua', 'hue', 'huh', 'hui', 'hum', 'humein', 'humne', 'hun', 'huye', 'huyi', 'i', \"i'd\", 'idk', 'ie', 'if', \"i'll\", \"i'm\", 'imo', 'in', 'inasmuch', 'inc', 'inhe', 'inhi', 'inho', 'inka', 'inkaa', 'inke', 'inki', 'inn', 'inner', 'inse', 'insofar', 'into', 'inward', 'is', 'ise', 'isi', 'iska', 'iskaa', 'iske', 'iski', 'isme', 'isn', 'isne', 'isnt', \"isn't\", 'iss', 'isse', 'issi', 'isski', 'it', \"it'd\", \"it'll\", 'itna', 'itne', 'itni', 'itno', 'its', \"it's\", 'itself', 'ityaadi', 'ityadi', \"i've\", 'ja', 'jaa', 'jab', 'jabh', 'jaha', 'jahaan', 'jahan', 'jaisa', 'jaise', 'jaisi', 'jata', 'jayega', 'jidhar', 'jin', 'jinhe', 'jinhi', 'jinho', 'jinhone', 'jinka', 'jinke', 'jinki', 'jinn', 'jis', 'jise', 'jiska', 'jiske', 'jiski', 'jisme', 'jiss', 'jisse', 'jitna', 'jitne', 'jitni', 'jo', 'just', 'jyaada', 'jyada', 'k', 'ka', 'kaafi', 'kab', 'kabhi', 'kafi', 'kaha', 'kahaa', 'kahaan', 'kahan', 'kahi', 'kahin', 'kahte', 'kaisa', 'kaise', 'kaisi', 'kal', 'kam', 'kar', 'kara', 'kare', 'karega', 'karegi', 'karen', 'karenge', 'kari', 'karke', 'karna', 'karne', 'karni', 'karo', 'karta', 'karte', 'karti', 'karu', 'karun', 'karunga', 'karungi', 'kaun', 'kaunsa', 'kayi', 'kch', 'ke', 'keep', 'keeps', 'keh', 'kehte', 'kept', 'khud', 'ki', 'kin', 'kine', 'kinhe', 'kinho', 'kinka', 'kinke', 'kinki', 'kinko', 'kinn', 'kino', 'kis', 'kise', 'kisi', 'kiska', 'kiske', 'kiski', 'kisko', 'kisliye', 'kisne', 'kitna', 'kitne', 'kitni', 'kitno', 'kiya', 'kiye', 'know', 'known', 'knows', 'ko', 'koi', 'kon', 'konsa', 'koyi', 'krna', 'krne', 'kuch', 'kuchch', 'kuchh', 'kul', 'kull', 'kya', 'kyaa', 'kyu', 'kyuki', 'kyun', 'kyunki', 'lagta', 'lagte', 'lagti', 'last', 'lately', 'later', 'le', 'least', 'lekar', 'lekin', 'less', 'lest', 'let', \"let's\", 'li', 'like', 'liked', 'likely', 'little', 'liya', 'liye', 'll', 'lo', 'log', 'logon', 'lol', 'look', 'looking', 'looks', 'ltd', 'lunga', 'm', 'maan', 'maana', 'maane', 'maani', 'maano', 'magar', 'mai', 'main', 'maine', 'mainly', 'mana', 'mane', 'mani', 'mano', 'many', 'mat', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'mein', 'mera', 'mere', 'merely', 'meri', 'might', 'mightn', 'mightnt', \"mightn't\", 'mil', 'mjhe', 'more', 'moreover', 'most', 'mostly', 'much', 'mujhe', 'must', 'mustn', 'mustnt', \"mustn't\", 'my', 'myself', 'na', 'naa', 'naah', 'nahi', 'nahin', 'nai', 'name', 'namely', 'nd', 'ne', 'near', 'nearly', 'necessary', 'neeche', 'need', 'needn', 'neednt', \"needn't\", 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nhi', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nope', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'par', 'pata', 'pe', 'pehla', 'pehle', 'pehli', 'people', 'per', 'perhaps', 'phla', 'phle', 'phli', 'placed', 'please', 'plus', 'poora', 'poori', 'provides', 'pura', 'puri', 'q', 'que', 'quite', 'raha', 'rahaa', 'rahe', 'rahi', 'rakh', 'rakha', 'rakhe', 'rakhen', 'rakhi', 'rakho', 'rather', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'rehte', 'rha', 'rhaa', 'rhe', 'rhi', 'ri', 'right', 's', 'sa', 'saara', 'saare', 'saath', 'sab', 'sabhi', 'sabse', 'sahi', 'said', 'sakta', 'saktaa', 'sakte', 'sakti', 'same', 'sang', 'sara', 'sath', 'saw', 'say', 'saying', 'says', 'se', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'shan', 'shant', \"shan't\", 'she', \"she's\", 'should', 'shouldn', 'shouldnt', \"shouldn't\", \"should've\", 'si', 'since', 'six', 'so', 'soch', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'still', 'sub', 'such', 'sup', 'sure', 't', 'tab', 'tabh', 'tak', 'take', 'taken', 'tarah', 'teen', 'teeno', 'teesra', 'teesre', 'teesri', 'tell', 'tends', 'tera', 'tere', 'teri', 'th', 'tha', 'than', 'thank', 'thanks', 'thanx', 'that', \"that'll\", 'thats', \"that's\", 'the', 'theek', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'theres', \"there's\", 'thereupon', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'thi', 'thik', 'thing', 'think', 'thinking', 'third', 'this', 'tho', 'thoda', 'thodi', 'thorough', 'thoroughly', 'those', 'though', 'thought', 'three', 'through', 'throughout', 'thru', 'thus', 'tjhe', 'to', 'together', 'toh', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'true', 'truly', 'try', 'trying', 'tu', 'tujhe', 'tum', 'tumhara', 'tumhare', 'tumhari', 'tune', 'twice', 'two', 'um', 'umm', 'un', 'under', 'unhe', 'unhi', 'unho', 'unhone', 'unka', 'unkaa', 'unke', 'unki', 'unko', 'unless', 'unlikely', 'unn', 'unse', 'until', 'unto', 'up', 'upar', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'usi', 'using', 'uska', 'uske', 'usne', 'uss', 'usse', 'ussi', 'usually', 'vaala', 'vaale', 'vaali', 'vahaan', 'vahan', 'vahi', 'vahin', 'vaisa', 'vaise', 'vaisi', 'vala', 'vale', 'vali', 'various', 've', 'very', 'via', 'viz', 'vo', 'waala', 'waale', 'waali', 'wagaira', 'wagairah', 'wagerah', 'waha', 'wahaan', 'wahan', 'wahi', 'wahin', 'waisa', 'waise', 'waisi', 'wala', 'wale', 'wali', 'want', 'wants', 'was', 'wasn', 'wasnt', \"wasn't\", 'way', 'we', \"we'd\", 'well', \"we'll\", 'went', 'were', \"we're\", 'weren', 'werent', \"weren't\", \"we've\", 'what', 'whatever', \"what's\", 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', \"where's\", 'whereupon', 'wherever', 'whether', 'which', 'while', 'who', 'whoever', 'whole', 'whom', \"who's\", 'whose', 'why', 'will', 'willing', 'with', 'within', 'without', 'wo', 'woh', 'wohi', 'won', 'wont', \"won't\", 'would', 'wouldn', 'wouldnt', \"wouldn't\", 'y', 'ya', 'yadi', 'yah', 'yaha', 'yahaan', 'yahan', 'yahi', 'yahin', 'ye', 'yeah', 'yeh', 'yehi', 'yes', 'yet', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\", 'yup']\n",
    "\n",
    "STOPWORDS = set(stopwordlist)\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda text: cleaning_stopwords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9b0aa",
   "metadata": {},
   "source": [
    "### Removing Numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e90b130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda text: cleaning_numbers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a4d69",
   "metadata": {},
   "source": [
    "### Removing repeating characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d02dff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = (word_tokenize(i) for i in df.tweets)\n",
    "df['tweets'] = df['tweets'].apply(nltk.word_tokenize)\n",
    "#df['tweets'] = df['tweets'].astype(str)\n",
    "\n",
    "pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "def reduce_sequence_word(word):\n",
    "    return ''.join([match.group()[:2] if len(match.group()) > 2 else match.group() for match in pattern.finditer(word)])\n",
    "\n",
    "def reduce_sequence_tweet(tweet):\n",
    "    return [reduce_sequence_word(word) for word in tweet]\n",
    "\n",
    "df.tweets = df.tweets.apply(lambda tweet: reduce_sequence_tweet(tweet))\n",
    "df['tweets'] = df['tweets'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43cf788",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test &&& Tokenizing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c73c726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=[\"'modi\", \"'ensure\", \"'kr\", \"'demonetization\", \"'gst\", \"'unthinkable\", \"'rates\", \"'garib\", \"'marr\", \"'jai\", \"'ni\", \"'garib\", \"'ni\", \"'rahegi\", \"'garibi\"], tags=[2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=3)\n",
    "\n",
    "# Creating a function for tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "# Tagging words:\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['tweets']), tags=[r.labels]), axis=1)\n",
    "\n",
    "train_tagged.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df251fa",
   "metadata": {},
   "source": [
    "# Doc2Vec:\n",
    "### Distributed Bag of Words (DBOW)\n",
    "Note: If dm=0, distributed bag of words (PV-DBOW) is used; if dm=1,‘distributed memory’ (PV-DM) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b7e65",
   "metadata": {},
   "source": [
    "### Building DBOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcbe2ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb62aa4460b4b87ae2d30def70f2e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3e06908bfe46f2b14768f5b5c5e051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab90c62d47445d4b8a8290f9bce1b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6f8e3014274edeb442f01d5a3918c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998b329aed404b5685d3af5d9218de2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a85809bb6b48e1a185320a1dbeeb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dabbe5ef2f4738bf7b1b340fd14b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07eaf6ba2751442ba21a960c9fcd5cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea2171d356f4ac1952847ef88514e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f2fbc0eb4454ba2f90adde8a70fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a7488bfdcb464fa8afaaf843e4ead7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57877ec637047f4af9410be6ef5d09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb395c5a32b4a16845e0225bcbb776b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901b740b1c754f6eacdb51027ed48542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2389277dfee64c79a65c738d1bf7dde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c59373cfae04a5daabd95cc03c08184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a29e81c0ac9441faf44ee86a1e5e466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a24cec442b3437db40f9111902a60ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3c73508a0c43f3b1fd9c01d89ebbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed23adea790d4cd497c3485aecfc15d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5b9c5c64d84a59b00b46ca74f9c636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e146a4007345cbb843c6bae4356d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de67d1ad661643aa8152dae9796a3f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9853b80d0e4d0e99b75fe343c050f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b48a98f15646299dff9dd2d715d80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b886177698c4d2999576655e6a301c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536811136a9441699c538d8bd98ef597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6169bed07e4ccd89b8c07aa119200f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f632f2630bf46d2ae936c2f347e58fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18da42b30a64c12ad6f2e8ea7cb6ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee49917ab8284b1282919988a1861aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec1a70",
   "metadata": {},
   "source": [
    "### Creating Final feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "883f5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Final Feature Vector for the Classifier\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "# Creating X_train, X_test, y_train, y_test\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3ab1e",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b95635bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[175  36  47  49   2  26  26]\n",
      " [ 74  63  33  26   1  15  30]\n",
      " [ 87  43  92  55   1  12  20]\n",
      " [ 98  37  51  95   6  37  22]\n",
      " [ 18   5   7   6  54   5   9]\n",
      " [ 57  24  34  41   2  58  23]\n",
      " [ 67  26  15  10   5  13  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.48      0.37       361\n",
      "           1       0.27      0.26      0.26       242\n",
      "           2       0.33      0.30      0.31       310\n",
      "           3       0.34      0.27      0.30       346\n",
      "           4       0.76      0.52      0.62       104\n",
      "           5       0.35      0.24      0.29       239\n",
      "           6       0.42      0.41      0.42       231\n",
      "\n",
      "    accuracy                           0.34      1833\n",
      "   macro avg       0.40      0.36      0.37      1833\n",
      "weighted avg       0.36      0.34      0.34      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[148  39  47  59   3  31  34]\n",
      " [ 60  60  36  32   0  17  37]\n",
      " [ 75  39 103  55   3  13  22]\n",
      " [ 90  33  55 102   5  39  22]\n",
      " [ 17   6   9   6  53   4   9]\n",
      " [ 48  24  37  40   2  64  24]\n",
      " [ 54  25  17  13   4  14 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.41      0.35       361\n",
      "           1       0.27      0.25      0.26       242\n",
      "           2       0.34      0.33      0.34       310\n",
      "           3       0.33      0.29      0.31       346\n",
      "           4       0.76      0.51      0.61       104\n",
      "           5       0.35      0.27      0.30       239\n",
      "           6       0.41      0.45      0.43       231\n",
      "\n",
      "    accuracy                           0.35      1833\n",
      "   macro avg       0.39      0.36      0.37      1833\n",
      "weighted avg       0.36      0.35      0.35      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[141  27  50  70   4  32  37]\n",
      " [ 69  50  39  34   1  19  30]\n",
      " [ 73  35 115  53   2  13  19]\n",
      " [ 90  29  54 115   5  39  14]\n",
      " [ 15   6  11   7  49   7   9]\n",
      " [ 48  16  39  49   2  67  18]\n",
      " [ 46  23  22  20   5  18  97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.39      0.33       361\n",
      "           1       0.27      0.21      0.23       242\n",
      "           2       0.35      0.37      0.36       310\n",
      "           3       0.33      0.33      0.33       346\n",
      "           4       0.72      0.47      0.57       104\n",
      "           5       0.34      0.28      0.31       239\n",
      "           6       0.43      0.42      0.43       231\n",
      "\n",
      "    accuracy                           0.35      1833\n",
      "   macro avg       0.39      0.35      0.37      1833\n",
      "weighted avg       0.35      0.35      0.35      1833\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 26min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.344790</td>\n",
       "      <td>{'C': 100, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.345881</td>\n",
       "      <td>{'C': 20, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.345881</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 30, 'n_e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0                   SVC    0.344790   \n",
       "1  logistics_regression    0.345881   \n",
       "2         random_forest    0.345881   \n",
       "\n",
       "                                         best_params  \n",
       "0         {'C': 100, 'gamma': 1, 'kernel': 'linear'}  \n",
       "1                   {'C': 20, 'solver': 'liblinear'}  \n",
       "2  {'criterion': 'entropy', 'max_depth': 30, 'n_e...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nFitting...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf36a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
